{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c8a3aa",
   "metadata": {},
   "source": [
    "<h1>Evolutionary Information Theory</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9313eb9",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>\n",
    "The purpose of this project is to merge evolutionary game theory with concepts from information theory. Specifically, Shannon's information entropy will be used as a metric to determine the success of agents over time (the payoff). In other words, this will test how how competitive and cooperative systems behave when information must be preserved over multiple rounds.\n",
    "\n",
    "While this is currently theoretical, it could potential have applications in linguistics, to help understand how languages evolve while continuing to convery the same information; political science and academic research, to understand the spread of false information among trusted sources; or even in biology, helping understand how DNA can survive unchanged throughtout generations.\n",
    "\n",
    "Before we dive into these potential applications, we must first understand the theoretical foundations of information theory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159b8a8",
   "metadata": {},
   "source": [
    "<h2>Shannon Entropy</h2>\n",
    "In order to understand Shannon entropy, we must first define the bit. A bit it a binary digit. That is a 1 or a 0. One binary digit can represent different states of the world. Take an event in which there is a 50-50 chance of an outcome occuring, say a coin toss. 1 could represent heads and 0 could represent tails. This means, only one bit is needed to describe the outcome of a coin toss. The probability of $n$ coin tosses would be $p=(1\\2)^n$. Each coin toss would require an additional binary digit to describe the outcome. For example, two heads would be represented as 11. Three tails would be represented as 000. One head, one tails, then 4 heads would be represented as 101111. n tails would be represeneted 0 ... 0 (n times).\n",
    "The information content, or information gain, of a particular outcome is like finding the number of binary yes/no questions required to resolve an issue. One unit of (binary) information gain is one bit. We can think of the information gain like the number of coin tosses or binary yes/no questions required to answer a question. For this reason we can say p=(1/2)^I\n",
    "Rearranging this formula we get $$ p=(1\\2)^I $$ => $$ 2^I = 1\\p $$ => $$ I = log{_2}{1\\p} $$ =>  $$ I = - log{_2}{p} $$ reference 3b1b\n",
    "Insert example with spinner\n",
    "We can say that if something has 3 bits of information, it is the same as asking 3 yes/no questions.\n",
    "The average information content assosicated with a variable is known as the Shannon entropy reference audiobook\n",
    "$$ H(x) = sum_{p(X=x) * I} = sum_{p(X=x) * log{_2}{1\\p(X=x)}} = - sum_{p(X=x) log{_2}{p(X=x)} $$\n",
    "For a random variable $X$, the entropy is\n",
    "$$ -H(X) := -\\sum_{x \\in X}p(x)\\log p(x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c5239",
   "metadata": {},
   "source": [
    "<h2>Hawk-Dove and Shannon Entropy</h2>\n",
    "The traditional Hawk-Dove ... The payoff matrix would look as follows: \n",
    "\n",
    "|  | Hawk | Dove |\n",
    "| --- | --- | --- |\n",
    "| Hawk | P1 | P2 |\n",
    "| Dove | P3 | P4 |\n",
    "\n",
    "This is a test edit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761998f",
   "metadata": {},
   "source": [
    "<h2>References</h2>\n",
    "\n",
    "- *The Selfish Gene*, Richard Dawkins\n",
    "- *Evolutionary Games and Population Genetics*, Steve Baigent\n",
    "- *The Science of Information: From Language to Black Holes*, The Great Courses Plus"
    "- *3Blue1Brown, Definition of a 'bit' in information theory, Available at: https://youtube.com/shorts/BTryyW7gqg4?si=ME8vv0QLUj3kMiNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a49ee0",
   "metadata": {},
   "source": [
    "<h2>Note</h2>\n",
    "This was the original idea for my undergraduate dissertation. However, I did not have enough time to explore the mathematics underlying this at the time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
